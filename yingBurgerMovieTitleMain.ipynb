{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation 3; Generate\n",
      "Path saved for Title Generation\n",
      "Time Spent = 0.0004770000000000607 sec.\n"
     ]
    }
   ],
   "source": [
    "# {'sci_fi': [[36, 'NN NN'], [9, 'NN'], [8, 'JJ NN'], [8, 'NR'], [7, 'NR NN'], [6, 'VV NN']], \n",
    "#'action': [[24, 'NN NN'], [8, 'VV NN'], [7, 'NN'], [6, 'NR'], [6, 'NN VV'], [5, 'NR NN']], \n",
    "#'adventure': [[19, 'NN NN'], [8, 'NR NN'], [5, 'NR'], [4, 'NN'], [3, 'JJ NN'], [3, 'VV NN']], \n",
    "#'horror': [[22, 'NN NN'], [11, 'NN'], [8, 'NR'], [7, 'NN VV'], [6, 'VV'], [5, 'VV NN']], \n",
    "#'comody': [[13, 'NN NN'], [8, 'JJ NN'], [6, 'NN'], [5, 'VV NN'], [4, 'NR'], [3, 'NN VV']], \n",
    "#'romance': [[11, 'NN NN'], [6, 'NR NN'], [4, 'VV NN'], [4, 'NN'], [1, 'NR NR NN'], [1, 'PN NT']]}\n",
    "# NN NR VV JJ\n",
    "import pickle\n",
    "import re\n",
    "import jieba\n",
    "from hanziconv import HanziConv\n",
    "import os\n",
    "import time\n",
    "#--------------set variables here--------------------------------------\n",
    "operationType=3  #1=yield training data 2=yield test data 3= yield generation data\n",
    "longTrainingInput=5\n",
    "shortTrainingInput=3\n",
    "generateInput=3\n",
    "movieTitlesFile='movie.txt'\n",
    "#-------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "#---------------programs starts below-------------------------------------\n",
    "#-------------------------------------------------------------------------\n",
    "#---if 1, gets the training movie titles in Eng. and Chi.-----------------\n",
    "#---if 2 or 3, save the path to Path--------------------------------------\n",
    "startTime=time.clock()\n",
    "if operationType==1:\n",
    "    print(\"Operation 1; Training; Preparing training data...\")\n",
    "    Path=\"./input/trainingData/\"\n",
    "\n",
    "    movieTitles=open(Path+movieTitlesFile,'r',encoding='utf-8')\n",
    "    titlelist=[]\n",
    "    titleDict={}\n",
    "    for title in movieTitles.readlines():                       #get movie names in Eng. and Chi. from movie.txt.\n",
    "        titlelist.append(title.split('\\t'))                     #split by tab\n",
    "    for i in titlelist:\n",
    "        tmp=i[1].strip(\"\\n\")                                    #remove \\n in titles\n",
    "        tmp=HanziConv.toSimplified(tmp)                         #Make it to simplified Chinese\n",
    "        i[1]=tmp \n",
    "    movieTitles.close()\n",
    "\n",
    "    for t in titlelist:                                         #save the titles to dictionary\n",
    "        titleDict.update({t[0]:t[1]})\n",
    "    print(\"Total movies in movie.txt =  \"+str(len(titleDict)))\n",
    "    file = os.listdir(Path)\n",
    "    englishname=[]\n",
    "    for f in file:                                              #Check if there are movie srt not included in movie.txt\n",
    "        if f.endswith(\"srt\"):\n",
    "            filename=str(f)\n",
    "            tmp=filename.strip(\"srt\")\n",
    "            tmp=tmp.strip(\".\")\n",
    "            englishname.append(tmp)\n",
    "    for name in englishname:\n",
    "        if name not in titleDict:\n",
    "            titleDict.update({name:'0'})                       #if not in movie.txt then add movie \n",
    "            print(name)                                        #English name:0 in dict. and print the new movie name\n",
    "    \n",
    "    movieTitles=open(Path+'movie.txt','w',encoding='utf-8')    \n",
    "    for k,v in titleDict.items():                              #------delete ':' in chinese title\n",
    "        temptitle=[]\n",
    "        for letter in v:\n",
    "            if \"：\" in letter:\n",
    "                pass\n",
    "            else:\n",
    "                temptitle.append(letter)\n",
    "        titleDict.update({k:\"\".join(temptitle)})                 \n",
    "        movieTitles.write(k+\"\\t\"+v+\"\\n\")                       #write the new dictionary to movie.txt\n",
    "    movieTitles.close()\n",
    "    print(\"After Checking, total training .srt in folder = \"+str(len(file)-1)) #-1 tp exclude movie.txt\n",
    "    print(\"Preparation done!\")\n",
    "elif operationType==2:\n",
    "    print(\"Operation 2; Testing\")\n",
    "    Path=\"./input/testData/\"\n",
    "    print(\"Path saved for Testing Data\")\n",
    "elif operationType==3:\n",
    "    print(\"Operation 3; Generate\")\n",
    "    Path=\"./input/forGeneration/\"\n",
    "    print(\"Path saved for Title Generation\")\n",
    "endtime=time.clock()\n",
    "print(\"Time Spent = \"+ str(endtime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Processing .srt files...\n",
      "Operation = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.572 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Moive number = 10\n",
      "Time Spent Processing Srt. = 1.3462020000000001 sec.\n",
      "Total Time Spent = 1.346442 sec.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import jieba\n",
    "from hanziconv import HanziConv\n",
    "import os\n",
    "#------------------------------Cleanup srt and get only chinese characters--------------------------------------\n",
    "#------------------------------Segment the words through Jieba--------------------------------------------------\n",
    "#------------------------------All words per movie saved to AllInput is for Jaccard similarity use later--------\n",
    "#------------------------------VectorInput is for the vector calculation later----------------------------------\n",
    "#------------------------------This is to prepare all the words for word2Vector calculation---------------------\n",
    "#------------------------------And words for jaccard similarity-------------------------------------------------\n",
    "startTime=time.clock()\n",
    "getPath=Path\n",
    "files = os.listdir(getPath)                              #get files from the directory depends on the operation\n",
    "AllInput=[]\n",
    "VectorInput=[]\n",
    "movieOrder=[]\n",
    "print(\"Start Processing .srt files...\")\n",
    "print(\"Operation = \"+str(operationType))\n",
    "for f in files:\n",
    "    if f.endswith(\"txt\"):                                #skip txt file\n",
    "        pass\n",
    "    else:\n",
    "        file=str(f)                                      #only process srt file\n",
    "        #print(file)\n",
    "        tmp=file.strip(\"srt\")\n",
    "        tmp=tmp.strip(\".\")\n",
    "        movieOrder.append(tmp)\n",
    "        testSubs=open(getPath+file, 'r',encoding='utf-8')\n",
    "        string=\"\"\n",
    "        tmp=[]\n",
    "        temp=[]\n",
    "        alll=[]\n",
    "        for i in testSubs.readlines():                  #append each line to tmp until \\n found\n",
    "            if i == '\\n':\n",
    "                if tmp==[''] or tmp==[]:\n",
    "                    pass\n",
    "                else:\n",
    "                    temp.append(tmp)                   #if \\n found, save tmp to temp \n",
    "                    tmp=[]                             #then empty tmp\n",
    "            else:\n",
    "                tmp.append(i)\n",
    "        tmp=[]\n",
    "        for line in temp: \n",
    "            tmp=[]                                              #get only chinese characters from the subtitles\n",
    "            for n in re.findall('[\\u4e00-\\u9fff]',str(line)):   #This removes the time stamp, \n",
    "                tmp.append(n)                                   #and other unnecessary symbols\n",
    "            string=''.join(tmp)\n",
    "            if string=='':\n",
    "                pass\n",
    "            else:\n",
    "                alll.append(string)                             #append each cleaned Chinese lines to alll list\n",
    "            string=\"\"\n",
    "            \n",
    "        tmpSeg=[]\n",
    "        newAllLines=[]\n",
    "        forVectorLines=[]\n",
    "        for line in alll:                                      #segment each line in alll list by jieba\n",
    "            str_in = str(line)\n",
    "            seg_list = jieba.cut_for_search(\"\".join(HanziConv.toSimplified(str_in)))  \n",
    "            for i in seg_list:\n",
    "                newAllLines.append(i)                         #new AllLines stores segmented sentences\n",
    "                forVectorLines.append(i)\n",
    "            forVectorLines.append(\"。\")\n",
    "        toSimp=[]\n",
    "        for word in newAllLines:\n",
    "            toSimp.append(word)\n",
    "        AllInput.append(toSimp)\n",
    "        toSimp=[]\n",
    "        for word in forVectorLines:                          \n",
    "            toSimp.append(word)\n",
    "        VectorInput.append(toSimp)\n",
    "print(\"Total Moive number = \"+str(len(AllInput)))\n",
    "midTime=time.clock()\n",
    "print(\"Time Spent Processing Srt. = \"+ str(midTime-startTime)+\" sec.\")\n",
    "if operationType==1:                                        #if operation is training,\n",
    "    print(\"Saving sentences to vectorInput.txt...\")         #save sentences for calculatiing vector later\n",
    "    outfile=open(\"vectorInput.txt\",\"w\",encoding=\"utf-8\")    #to file: vectorInput\n",
    "    for i in VectorInput:\n",
    "        for word in i:\n",
    "            outfile.write(str(word)+\" \")\n",
    "    outfile.close()\n",
    "    endTime=time.clock()\n",
    "    print(\"Time Spent Saving to vectorInput.txt= \"+ str(endTime-midTime)+\" sec.\")\n",
    "endTime=time.clock()\n",
    "print(\"Total Time Spent = \"+ str(endTime-startTime)+\" sec.\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading 300_selected...\n",
      "Operation = 3\n",
      "Done loading! Words saved to variable: keywordList\n",
      "Total Time Spent = 0.002857999999999805 sec.\n"
     ]
    }
   ],
   "source": [
    "#---------------load preprocessed 300_selected words for each type of movies------------------------\n",
    "#save 300 words to list\n",
    "import pickle\n",
    "print(\"Start loading 300_selected...\")\n",
    "print(\"Operation = \"+str(operationType))\n",
    "startTime=time.clock()\n",
    "words300In=open(\"300_Selected.pickle\",'rb')\n",
    "wordin=pickle.load(words300In)\n",
    "movieType=['action','adventure','comedy','horror','romance','sci_fi']\n",
    "keywordList={}\n",
    "for tp in movieType:\n",
    "    tmpKeys=[]\n",
    "    for k,v in wordin[tp].items():\n",
    "        tmpKeys.append(k)\n",
    "    keywordList.update({tp:tmpKeys})\n",
    "print(\"Done loading! Words saved to variable: keywordList\")\n",
    "endTime=time.clock()   \n",
    "print(\"Total Time Spent = \"+ str(endTime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating similarity to types...\n",
      "Operation = 3\n",
      "Total movie processed = 10\n",
      "Total Time Spent = 0.031115000000000226 sec.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------Jaccard similarity-------------------------------\n",
    "#----------------------------------Use Jaccard to find the type of each input movie-----\n",
    "#----------------------------------Only for operation 2 & 3 ----------------------------\n",
    "from __future__ import division\n",
    "import string\n",
    "import math\n",
    "\n",
    "def jaccard_similarity(query, document):#---the bigger the score, the more similar\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "startTime=time.clock()\n",
    "print(\"Start calculating similarity to types...\")\n",
    "movieType=['action','adventure','comedy','horror','romance','sci_fi']\n",
    "scores={}\n",
    "FoundTypes=[]\n",
    "cnt=0\n",
    "for movie in AllInput:\n",
    "    cnt+=1\n",
    "    for ty in movieType:\n",
    "        score=jaccard_similarity(movie,keywordList[ty])\n",
    "        scores.update({ty:score})\n",
    "        #print(\"Type: \"+ty+\"\\t - Score: \\t\"+ str(score))\n",
    "    sortedD=sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    foundType=sortedD[0][0]\n",
    "    #print(\"第:\"+str(cnt)+\"部電影 -Type Found! :\"+foundType)\n",
    "    FoundTypes.append(foundType)\n",
    "print(\"Operation = \"+str(operationType))\n",
    "print(\"Total movie processed = \" + str(cnt))\n",
    "endTime=time.clock()   \n",
    "print(\"Total Time Spent = \"+ str(endTime-startTime)+\" sec.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation = 3\n",
      "Start calculating similarity to movies...\n",
      "Total Time Spent = 1.3786129999999996 sec.\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------find most similar movie----------------------------------------\n",
    "#--------------------------------used previously saved AllInput variable------------------------------\n",
    "AllsubsIn=open(\"AllSubWordsSegmented.pickle\",'rb')\n",
    "WordsofMovies=pickle.load(AllsubsIn)\n",
    "movieSimilarity={}\n",
    "topmovies={}\n",
    "tmpsim=[]\n",
    "testandGenerate=[]\n",
    "\n",
    "startTime=time.clock()\n",
    "print(\"Operation = \"+str(operationType))\n",
    "print(\"Start calculating similarity to movies...\")\n",
    "for i in range(len(AllInput)):\n",
    "    tmpsim=[]\n",
    "    movieSimilarity={}\n",
    "    for k,v in WordsofMovies[FoundTypes[i]].items():\n",
    "        tmpScore=jaccard_similarity(AllInput[i],v)\n",
    "        movieSimilarity.update({k:tmpScore})\n",
    "    sortedSimilarity=sorted(movieSimilarity.items(), key=lambda x: x[1], reverse=True)\n",
    "    tmpsim.append(FoundTypes[i])\n",
    "    if operationType==1:                                    #for training\n",
    "        tmpsim.append(sortedSimilarity[0:5])                #change the length to get more input for S2s training\n",
    "        sortedSimilarity=[]\n",
    "        topmovies.update({str(i+1):tmpsim})\n",
    "    elif operationType==2 or operationType==3:             #for test or generate\n",
    "        tmpsim.append(sortedSimilarity[0])                 #get the most similar movie and use the overlapping \n",
    "        sortedSimilarity=[]                                #words as the input for S2s\n",
    "        topmovies.update({str(i+1):tmpsim})\n",
    "#print(topmovies)\n",
    "AllsubsIn.close()\n",
    "endTime=time.clock()   \n",
    "print(\"Total Time Spent = \"+ str(endTime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting input word selection...\n",
      "Operation = 3\n",
      "Start Random Process\n",
      "Processed movies = 10\n",
      "Total Time Spent preparing generation data = 0.32951200000000025 sec.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pickle\n",
    "#--------------------------------get random 10 key words from the top similar movies---------------------\n",
    "MovieWordsRef=open('AllSubWordsSegmented.pickle','rb')\n",
    "MovieWordsload=pickle.load(MovieWordsRef)\n",
    "#-----------operation 1----------------------------\n",
    "startTime=time.clock()\n",
    "if operationType==1:                                            #for getting training data\n",
    "    print(\"Starting input word selection; for Op 1...\")\n",
    "    S2sInput={}                                                 #This gets the words of each most similar movies\n",
    "    tmpWord=[]                                                  #that overlaps with the 300_selected words    \n",
    "    tmpallWords=[]\n",
    "    for k,v in topmovies.items():\n",
    "        tmpallWords=[]\n",
    "        MoType=v[0]\n",
    "        for i in range(len(v[1])):\n",
    "            mv=v[1][i][0]\n",
    "            tmpWord=[]\n",
    "            for wd in keywordList[MoType]:\n",
    "                if wd in MovieWordsload[MoType][mv]:\n",
    "                    tmpWord.append(wd)\n",
    "            tmpallWords.append(tmpWord)\n",
    "        S2sInput.update({k:tmpallWords})                      #---got similar words between 300 and the movies\n",
    "           \n",
    "    totalRandom={}\n",
    "    print(\"Start 1st Random Process...\")\n",
    "    cnt=0\n",
    "    print(\"Preparing long training input\")\n",
    "    for k,v in S2sInput.items():                              #---get words out of those words\n",
    "        tempoList=[]\n",
    "        cnt+=1\n",
    "        for corpus in v:\n",
    "            listR=random.sample(corpus, longTrainingInput)    #get 5 words for input\n",
    "            tempoList.append(listR)\n",
    "        totalRandom.update({k:tempoList})\n",
    "    print(\"Processed movies = \" + str(cnt))\n",
    "    secTotalRandom={}\n",
    "    print(\"Start 2nd Random Process...\")\n",
    "    cnt=0\n",
    "    print(\"Preparing short training input\")\n",
    "    for k,v in S2sInput.items():\n",
    "        tempoList=[]\n",
    "        cnt+=1\n",
    "        for corpus in v:\n",
    "            listR=random.sample(corpus, shortTrainingInput)     #get 3 wotds for input\n",
    "            tempoList.append(listR)\n",
    "        secTotalRandom.update({k:tempoList})\n",
    "    endTime=time.clock()   \n",
    "    print(\"Processed movies = \" + str(cnt))\n",
    "    print(\"Total Time Spent preparing training data = \"+ str(endTime-startTime)+\" sec.\")\n",
    "#-----------operation 2 or 3----------------------------\n",
    "elif operationType==2 or operationType==3:                   #for test or generation data\n",
    "    print(\"Starting input word selection...\")\n",
    "    print(\"Operation = \" +str(operationType))\n",
    "    S2sInput={}\n",
    "    tmpWord=[]\n",
    "    tmpallWords=[]\n",
    "    for k,v in topmovies.items():\n",
    "        tmpallWords=[]\n",
    "        MoType=v[0]\n",
    "        #for i in range(len(v[1])):\n",
    "        mv=v[1][0]\n",
    "        tmpWord=[]\n",
    "        for wd in keywordList[MoType]:\n",
    "            if wd in MovieWordsload[MoType][mv]:\n",
    "                tmpWord.append(wd)\n",
    "        tmpallWords.append(tmpWord)\n",
    "        S2sInput.update({k:tmpallWords})                    #---got similar words between 300 and the movies\n",
    "\n",
    "    totalRandom={}\n",
    "    print(\"Start Random Process\")\n",
    "    cnt=0\n",
    "    for k,v in S2sInput.items():\n",
    "        tempoList=[]\n",
    "        cnt+=1\n",
    "        for corpus in v:\n",
    "            listR=random.sample(corpus, generateInput)      #---get 2 words for input\n",
    "            tempoList.append(listR)\n",
    "        totalRandom.update({k:tempoList})\n",
    "    endTime=time.clock()   \n",
    "    print(\"Processed movies = \" + str(cnt))\n",
    "    print(\"Total Time Spent preparing generation data = \"+ str(endTime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation 3 Starts...\n",
      "Operation 3 Done...\n",
      "Total Time Spent outputing data = 0.0011100000000006105 sec.\n"
     ]
    }
   ],
   "source": [
    "#-------------------------Out to Sequence2Sequence use titleDict to find title in Chinese\n",
    "#This part is more for training the S2s, real execution of S2s generation needs no target\n",
    "startTime=time.clock()\n",
    "if operationType==1:\n",
    "    print(\"Operation \"+str(operationType)+\" Starts...\")\n",
    "    preS2s={}\n",
    "    preS2s2={}\n",
    "    target_line_dict={}\n",
    "    target_line_dict2={}\n",
    "    S2sInput=open(\"S2sTrainingInput.txt\",'w',encoding=\"utf-8\")\n",
    "    for i in range(len(totalRandom)):\n",
    "        preS2s.update({movieOrder[i]:totalRandom[str(i+1)]})\n",
    "    for k,v in preS2s.items():\n",
    "        target_line_dict.update({titleDict[k]:v})\n",
    "    #---------------------------\n",
    "    for i in range(len(secTotalRandom)):\n",
    "        preS2s2.update({movieOrder[i]:secTotalRandom[str(i+1)]})\n",
    "    for k,v in preS2s2.items():\n",
    "        target_line_dict2.update({titleDict[k]:v})\n",
    "    #--------------------------\n",
    "    for k,v in target_line_dict.items():\n",
    "        tmptitle=[]\n",
    "        for w in k:\n",
    "            if w == \":\" or w == \"2\" or w ==\"3\" or w ==\"4\" or w ==\"！\" or w ==\"?\" or w == \"1\" or w == \"5\" or w == \"7\" or w == \"0\" or w == \"8\" or w == \"9\" or w == \"6\" or w == \"X\":\n",
    "                pass\n",
    "            else:\n",
    "                tmptitle.append(w)\n",
    "        k_in=\"\".join(tmptitle)  \n",
    "        seg_k = jieba.cut(k_in,cut_all=False)\n",
    "        mtitle=\" \".join(seg_k)\n",
    "        for l in v:\n",
    "           #print(\" \".join(l)+\" | \"+mtitle)\n",
    "            S2sInput.write(\" \".join(l)+\" | \"+mtitle+\"\\n\")\n",
    "    #----------------------------------------------\n",
    "    for k,v in target_line_dict2.items():\n",
    "        tmptitle=[]\n",
    "        for w in k:\n",
    "            if w == \":\" or w == \"2\" or w ==\"3\" or w ==\"4\" or w ==\"！\" or w ==\"?\" or w == \"1\" or w == \"5\" or w == \"7\" or w == \"0\" or w == \"8\" or w == \"9\" or w == \"6\" or w == \"X\":\n",
    "                pass\n",
    "            else:\n",
    "                tmptitle.append(w)\n",
    "        k_in=\"\".join(tmptitle)  \n",
    "        seg_k = jieba.cut(k_in,cut_all=False)\n",
    "        mtitle=\" \".join(seg_k)\n",
    "        mtitle=mtitle.split()\n",
    "        mtitle=str(mtitle[0])\n",
    "        for l in v:\n",
    "            #print(\" \".join(l)+\" | \"+mtitle)\n",
    "            S2sInput.write(\" \".join(l)+\" | \"+mtitle+\"\\n\")\n",
    "    S2sInput.close()\n",
    "    print(\"Operation \"+str(operationType)+\" Done...\")\n",
    "#--------------------------------------------------------Op 2 or 3-----------------------------\n",
    "elif operationType==2 or operationType==3:\n",
    "    print(\"Operation \"+str(operationType)+\" Starts...\")\n",
    "    S2sInput=open(\"S2sTestInput.txt\",'w',encoding=\"utf-8\")\n",
    "    preS2s={}\n",
    "    target_line_dict={}\n",
    "    for i in range(len(totalRandom)):\n",
    "        preS2s.update({movieOrder[i]:totalRandom[str(i+1)]})\n",
    "    for k,v in preS2s.items():\n",
    "        target_line_dict.update({k:v})\n",
    "    for k,v in target_line_dict.items():\n",
    "        for l in v:\n",
    "            #print(\" \".join(l)+\" |\")\n",
    "            S2sInput.write(\" \".join(l)+\" |\\n\")\n",
    "    S2sInput.close()\n",
    "    print(\"Operation \"+str(operationType)+\" Done...\")\n",
    "#-----------to s2s input done\n",
    "endTime=time.clock()\n",
    "print(\"Total Time Spent outputing data = \"+ str(endTime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector preparation done!\n",
      "Total Time Spent = 0.00028100000000019776 sec.\n"
     ]
    }
   ],
   "source": [
    "#prepare vector.bin\n",
    "#password=mouse54321\n",
    "import getpass\n",
    "import os\n",
    "startTime=time.clock()\n",
    "if operationType==1:\n",
    "    password = getpass.getpass()\n",
    "    command=\"sudo -S ./ChatBotCourse-master/word2vec/word2vec -train ./vectorInput.txt -output vectors.bin -cbow 1 -size 200 -window 8 -negative 25 -hs 0 -sample 1e-5 -threads 20 -binary 1 -iter 15\"\n",
    "    os.system('echo %s | %s' % (password, command))\n",
    "elif operationType==2 or operationType==3:\n",
    "    pass\n",
    "\n",
    "print(\"Vector preparation done!\")\n",
    "endTime=time.clock()\n",
    "print(\"Total Time Spent = \"+ str(endTime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ymc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-01-31 13:32:44.673253: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "begin load vectors\n",
      "words = 31948\n",
      "size = 200\n",
      "load vectors finish\n",
      "\n",
      "predict answer\n",
      "\n",
      "干活 0.2078247447905392 0.9414782681835098\n",
      "启示录 0.3427040660677401 0.41106948246021013\n",
      "有钱 0.2816311909595598 0.15946990456335255\n",
      "太久 0.2708094404751138 0.06386107220210724\n",
      "拖 0.2553119397095464 0.028170949338043722\n",
      "未来 0.3075988194645857 0.011873412584381095\n",
      "\n",
      "predict answer\n",
      "\n",
      "失去 0.2563361124987004 0.8685160350530305\n",
      "启示录 0.4957927498887571 0.5037788394813076\n",
      "扩散 0.3990382133461168 0.17135288261349135\n",
      "令 0.3564704361430828 0.06773989611219283\n",
      "赚 0.25834124276617276 0.03183639491393061\n",
      "空气 0.2612764835016974 0.012290096628838194\n",
      "\n",
      "predict answer\n",
      "\n",
      "年前 0.26760880247032975 0.8155458322672458\n",
      "启示录 0.4648976091920191 0.3916225653284473\n",
      "怪物 0.3326037770843572 0.15198832033965873\n",
      "这么 0.3950768230897447 0.06937687276421849\n",
      "没有 0.39236354036520577 0.029157290908939048\n",
      "时光 0.4591099633434598 0.012747059644486154\n",
      "\n",
      "predict answer\n",
      "\n",
      "继承 0.26291240835193036 0.7172508046362647\n",
      "急速 0.4373846082933796 0.36181566117705327\n",
      "公里 0.30719018690072714 0.118508421580685\n",
      "温暖 0.44087453400914617 0.04897688517588912\n",
      "采取 0.40541708164389034 0.0219356207333726\n",
      "时光 0.4547298290335606 0.010408768460629051\n",
      "\n",
      "predict answer\n",
      "\n",
      "在 0.2867378588410698 0.8480373390692355\n",
      "急速 0.3733540656662081 0.36538176422336927\n",
      "大脑 0.33404879702111046 0.1402284998219487\n",
      "忧郁 0.3809725865196173 0.05091081502595483\n",
      "没有 0.32914497879812576 0.02158972906265286\n",
      "未来 0.3954496388361417 0.008225617779004397\n",
      "\n",
      "predict answer\n",
      "\n",
      "恋人 0.3887292661051984 0.906003949236342\n",
      "与 0.5469573308439363 0.4074224170164677\n",
      "第四 0.40812059057760436 0.17381003783650772\n",
      "天空 0.3791800283971546 0.06888591034471882\n",
      "饥饿 0.408346273515834 0.028989273866048673\n",
      "的 0.5129940236587213 0.01563109994494541\n",
      "\n",
      "predict answer\n",
      "\n",
      "幸福 0.27120269374068423 1.0448356727171122\n",
      "重量级 0.35712580380317244 0.48390919062082216\n",
      "就行了 0.3521834507434605 0.21513656354985092\n",
      "格列佛 0.2333074547086322 0.08305395830309632\n",
      "放风 0.3116438795227397 0.037439104200259685\n",
      "流水 0.23613674288502806 0.01746631185553809\n",
      "\n",
      "predict answer\n",
      "\n",
      "王子 0.2517035935306179 0.9438366477780176\n",
      "诸神 0.3953494957754502 0.504107979105977\n",
      "一击 0.38186866004827275 0.2125966916934728\n",
      "黎明 0.3670537743823142 0.08563891589816895\n",
      "战役 0.32881835916823693 0.03287288208343905\n",
      "获得 0.4428738329676509 0.014643858163916295\n",
      "\n",
      "predict answer\n",
      "\n",
      "童贞 0.31017653091752934 0.8125218828498276\n",
      "与 0.5597983903177739 0.39352774743961394\n",
      "山 0.30987362688879616 0.14289970695540558\n",
      "人生 0.375022859668958 0.061315516451167444\n",
      "时光 0.4357913573886555 0.024911809771404104\n",
      "的 0.3617669136554345 0.01090009286637883\n",
      "\n",
      "predict answer\n",
      "\n",
      "战争 0.2956127902482633 0.8895570557417164\n",
      "与 0.4407491192201424 0.37811068796619884\n",
      "极限 0.3135479267325959 0.14106274607203156\n",
      "人生 0.34600785093148756 0.06822359336853438\n",
      "没有 0.3022804008431948 0.027260387647275224\n",
      "未来 0.5155120206183406 0.014116155887702727\n",
      "Time Spent = 1.2660979999999995 sec.\n"
     ]
    }
   ],
   "source": [
    "#Run generator or train\n",
    "startTime=time.clock()\n",
    "if operationType==1:\n",
    "    !python \"ChatBotCourse-master/chatbotv2/my_seq2seq_v5.py\" train\n",
    "if operationType==2 or operationType==3:\n",
    "    !python \"ChatBotCourse-master/chatbotv2/my_seq2seq_v5.py\" test \"ChatBotCourse-master/chatbotv2/S2sTestInput.txt\"\n",
    "endtime=time.clock()\n",
    "print(\"Time Spent = \"+ str(endtime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All title saved to list for Post_Tag!\n",
      "Post_tagging Starts...\n",
      "Post_tagging Done!\n",
      "Time Spent = 0.002813999999999872 sec.\n"
     ]
    }
   ],
   "source": [
    "#--------get output from s2s and generate title\n",
    "\n",
    "import jieba\n",
    "import jieba.posseg\n",
    "import itertools\n",
    "import random\n",
    "import copy\n",
    "# r = (\"r\")\n",
    "# v = (\"s v n\")\n",
    "# a = (\"a\")\n",
    "# t = (\"t\")\n",
    "# s = (\"s v n\")\n",
    "# n = (\"s v n\")\n",
    "#-----collect have the most common combination of movie titles\n",
    "startTime=time.clock()\n",
    "collect = [['nrt'],['nr','n'],['vn'],['ns','vn'],['a','ns'],['a','n'],[\"s\",\"v\",\"n\"],['v','c','ns'],['n','n'],['v'],['n'],[\"r\",\"a\",\"v\",\"n\"],['sv','ns'],['ns'],['a']]\n",
    "#'r':0,'n':0,'v':0,'a':0,'t':0,'s':0\n",
    "\n",
    "f = open('output.txt','r',encoding = 'utf-8')\n",
    "movie_list = []                                   #save output from s2s to list and get the post_tag of the words\n",
    "for text in f:\n",
    "    \n",
    "    text = text.strip('\\n')\n",
    "    tmp = text.split(\" \")\n",
    "    #print(tmp)\n",
    "    for i in range(0,len(tmp)):\n",
    "        if(tmp[i] != ''):\n",
    "            movie_list.append(tmp[i])\n",
    "    \n",
    "print(\"All title saved to list for Post_Tag!\")\n",
    "print(\"Post_tagging Starts...\")\n",
    "d =[]\n",
    "\n",
    "word_list = []\n",
    "pos = []\n",
    "\n",
    "for i in range(len(movie_list)):                  #start pos_tagging\n",
    "    seg = jieba.posseg.cut(movie_list[i])\n",
    "    aa = []\n",
    "    for j in seg:\n",
    "        if(movie_list[i] == '之'):\n",
    "            j.flag = 'c'\n",
    "        aa.append(j.word)\n",
    "        aa.append(j.flag)\n",
    "        d.append(j.flag)\n",
    "        word_list.append(j.word)\n",
    "        break\n",
    "print(\"Post_tagging Done!\")\n",
    "\n",
    "\n",
    "endtime=time.clock()\n",
    "print(\"Time Spent = \"+ str(endtime-startTime)+\" sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "太久启示录\n",
      "启示录空气\n",
      "怪物时光\n",
      "采取\n",
      "忧郁大脑\n",
      "饥饿恋人\n",
      "格列佛流水\n",
      "王子战役\n",
      "童贞山\n",
      "极限人生\n"
     ]
    }
   ],
   "source": [
    "#---choose best combination\n",
    "from hanziconv import HanziConv\n",
    "opp  = open(\"answer.txt\",'w',encoding ='utf-8')\n",
    "combinations = []\n",
    "#print(d)\n",
    "for i in range(int(len(word_list)/6)):\n",
    "    tagging = {}\n",
    "    clock = 0\n",
    "    for x in word_list[i*6:i*6+6]:\n",
    "        temp = {}\n",
    "        #print(d[i*6+x])\n",
    "        #print(x)\n",
    "        #print(x)\n",
    "        if d[i*6+clock] not in tagging:\n",
    "            t = []\n",
    "            t.append(x)\n",
    "            temp['count'] = 1 \n",
    "            temp['word'] = t\n",
    "            tagging[d[i*6+clock]] = temp\n",
    "        else:\n",
    "            tagging[d[i*6+clock]]['count'] += 1 \n",
    "            tagging[d[i*6+clock]]['word'].append(x)\n",
    "        clock +=1\n",
    "            \n",
    "    #print(tagging)\n",
    "   \n",
    "    tag = copy.deepcopy(tagging)\n",
    "    for x in collect:\n",
    "        answer = []\n",
    "        index = len(x)\n",
    "        #print(\" -- - - - - - - -  - -\")\n",
    "        for y in x:\n",
    "            #print(y)\n",
    "            if(y in tag and tag[y]['count']>0):\n",
    "                index -= 1\n",
    "                \n",
    "                num = random.randint(0,100)%(tag[y]['count'])\n",
    "                #print(tag[y]['count'])\n",
    "                answer.append(tag[y]['word'][num])\n",
    "                tag[y]['word'].remove(tag[y]['word'][num])\n",
    "                tag[y]['count'] -=1\n",
    "                \n",
    "            else:\n",
    "                #print(\"null\")\n",
    "                tag = copy.deepcopy(tagging)\n",
    "                #print(\"++++++:\" + str(tagging))\n",
    "                break\n",
    "        if(index == 0 ):\n",
    "            tag = copy.deepcopy(tagging)\n",
    "            break\n",
    "\n",
    "    #print(answer)\n",
    "    write_data =\"\"\n",
    "    for x in answer:\n",
    "        write_data += x\n",
    "    print(write_data)\n",
    "    opp.write(str(i+1)+'\\t' +str(HanziConv.toTraditional(write_data)) +'\\n')\n",
    "    #tmp = itertools.combinations(word_list[i*6:i*6+6], 3)\n",
    "opp.close() \n",
    "#     for x in collect:\n",
    "#         for y in x:\n",
    "#             for i in tmp:\n",
    "#                 if(y==d[i[0]]):\n",
    "#                 print(i)\n",
    "#                 combinations.append((i[0],i[1]))\n",
    "#                 combinations.append((i[1],i[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
